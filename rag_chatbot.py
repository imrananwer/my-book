# rag_chatbot.py

import os
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from dotenv import load_dotenv

# Load environment variables from .env
load_dotenv()
CLAUDE_API_KEY = os.getenv("CLAUDE_API_KEY")
QDRANT_URL = os.getenv("QDRANT_URL", "http://localhost:6333")
QDRANT_API_KEY = os.getenv("QDRANT_API_KEY", "")

# Validate API key
if not CLAUDE_API_KEY:
    raise ValueError("CLAUDE_API_KEY not set in .env file!")

app = FastAPI(title="RAG Chatbot")

# Request model
class Query(BaseModel):
    question: str
    context_text: str = ""  # Optional user-selected text

# Dummy response function (replace with real Claude/Gemini + Qdrant integration)
def get_rag_answer(question: str, context_text: str = "") -> str:
    """
    This function simulates a RAG answer.
    Later you can connect Claude/Gemini API and Qdrant vector search here.
    """
    if context_text:
        return f"Answer based on selected text: {context_text}"
    return f"Answer generated by Claude/Gemini for: {question}"

# API endpoint
@app.post("/ask")
async def ask(query: Query):
    try:
        answer = get_rag_answer(query.question, query.context_text)
        return {"question": query.question, "answer": answer}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Run locally using:
# uvicorn rag_chatbot:app --reload --host 0.0.0.0 --port 8000
